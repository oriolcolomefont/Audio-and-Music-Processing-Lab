{"cells":[{"cell_type":"markdown","metadata":{"id":"3CVvi4YnddIp"},"source":["# 2) Analyze source collection and target file\n","\n","This notebook includes the code to analyze the collection of sounds compiled in the previous notebook and that will be later used as the source collection in our audio mosaicing code. The notebook also contains the code to analyze the target audio file that will be later reconstructed using sound chunks from the source collection.\n","\n","The audio analysis carried out in this notebook uses the Pythonn bindings of the Essentia library which was introduced in the first session of AMPLAB. Please make sure you checked the [Essentia Python tutorial](https://essentia.upf.edu/documentation/essentia_python_tutorial.html) to get familiarized with using Essentia in Python. Also useful is to always have a browser tab opened with Essentia's [Algorithms Reference](https://essentia.upf.edu/documentation/algorithms_reference.html) documentation page."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-t6MK-9Jdg2q"},"outputs":[],"source":["# Essentia\n","!pip install essentia\n","# Freesound-python\n","!pip install git+https://github.com/mtg/freesound-python.git\n","# Mount drive and cd to notebook folder\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd '/content/drive/MyDrive/SMC/AMPLab2324/AMPLAB 2024 Freesound session'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Ag-UHBDddIp"},"outputs":[],"source":["import pandas as pd\n","import essentia\n","import essentia.standard as estd\n","import matplotlib.pyplot as plt\n","from IPython.display import display, Audio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s3i5jhmqddIq"},"outputs":[],"source":["# Define here our sound analysis function\n","# NOTE: remember that if you update this function and want to run a new analysis you'll need to re-run both\n","# this cell and the cells below that carry out the audio analysis and that call the analysis function.\n","# After analyzing the source collection or the target file, make sure to correct descriptors have been\n","# extracted by checking the DataFrame contents. DataFrame contents can be printed on screen as a table\n","# using 'display(data_frame_object)'\n","\n","def analyze_sound(audio_path, frame_size=None, audio_id=None, sync_with_beats=False):\n","    \"\"\"Analyze the audio file given in 'sound_path'.\n","    Use the parameter 'frame_size' to set the size of the chunks in which the audio will\n","    be split for analysis. If no frame_size is given, the whole audio will be analyzed as\n","    a single frame.\n","    Use the 'audio_id' parameter to pass a custom identifier for the audio that will be\n","    included in the analysis results. This can be useful to later identify to which file an analysis belongs.\n","    \"\"\"\n","    analysis_output = []  # Here we'll store the analysis results for each chunk (frame) of the audio file\n","\n","    # Load audio file\n","    loader = estd.MonoLoader(filename=audio_path)\n","    audio = loader()\n","\n","    # Some processing of frame_size parameter to avoid later problems\n","    if frame_size is None:\n","        frame_size = len(audio)  # If no frame_size is given use no frames (analyze all audio at once)\n","    if frame_size % 2 != 0:\n","        frame_size = frame_size + 1 # Make frame size even\n","\n","    # Calculate the start and end samples for each equally-spaced audio frame\n","    if sync_with_beats:\n","      beat_tracker_algo = estd.BeatTrackerDegara()\n","      beat_positions = beat_tracker_algo(audio)\n","      beat_positions = [int(round(position * 44100)) for position in beat_positions]\n","      frame_start_end_samples = zip(beat_positions[:-1], beat_positions[1:])\n","    else:\n","      frame_start_samples = range(0, len(audio), frame_size)\n","      frame_start_end_samples = zip(frame_start_samples[:-1], frame_start_samples[1:])\n","\n","    # Iterate over audio frames and analyze each one\n","    for count, (fstart, fend) in enumerate(frame_start_end_samples):\n","\n","        # Get corresponding audio chunk and initialize dictionary to sotre analysis results with some basic metadata\n","        frame = audio[fstart:fend]\n","        frame_output = {\n","            'freesound_id': audio_id,\n","            'id': '{0}_f{1}'.format(audio_id, count),\n","            'path': audio_path,\n","            'start_sample': fstart,\n","            'end_sample': fend,\n","        }\n","\n","        # Extract loudness\n","        loudness_algo = estd.Loudness()\n","        loudness = loudness_algo(frame)\n","        frame_output['loudness'] = loudness / len(frame)  # Normnalize by length of frame\n","\n","        # Extract MFCC coefficients\n","        w_algo = estd.Windowing(type = 'hann')\n","        spectrum_algo = estd.Spectrum()\n","        mfcc_algo = estd.MFCC()\n","        spec = spectrum_algo(w_algo(frame))\n","        _, mfcc_coeffs = mfcc_algo(spec)\n","        frame_output.update({'mfcc_{0}'.format(j): mfcc_coeffs[j] for j in range(0, len(mfcc_coeffs))})\n","\n","        # Extract other features here and add to 'frame_output' dictionary\n","        # ...\n","\n","        # Add frame analysis results to output\n","        analysis_output.append(frame_output)\n","\n","    return analysis_output\n"]},{"cell_type":"markdown","metadata":{"id":"w9cZSc5PddIq"},"source":["## Analyze source collection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q2jZIwLvddIr","scrolled":false},"outputs":[],"source":["DATAFRAME_FILENAME = 'dataframe.csv'  # DataFrame file of the sound source collection to analyze\n","DATAFRAME_SOURCE_FILENAME = 'dataframe_source.csv'  # DataFrame file where to store the results of our analysis\n","\n","# Load the DataFrame of the sound source collection created in previous notebook and analyze all sound files in it\n","df = pd.read_csv(open(DATAFRAME_FILENAME), index_col=0)\n","analyses = []\n","for i in range(0, len(df)):\n","    sound = df.iloc[i]  # Get DataFrame sound at position 'i'\n","    print('Analyzing sound with id {0} [{1}/{2}]'.format(sound['freesound_id'], i + 1, len(df)))\n","    analysis_output = analyze_sound(sound['path'], frame_size=8192, audio_id=sound['freesound_id'])  # Split audio in chunks of 8192 samples (~185ms)\n","    analyses += analysis_output\n","\n","# Store analysis results in a new Pandas DataFrame and save it\n","df_source = pd.DataFrame(analyses)\n","df_source.to_csv(DATAFRAME_SOURCE_FILENAME)\n","print('Saved source DataFrame with {0} entries! {1}'.format(len(df_source), DATAFRAME_SOURCE_FILENAME))\n","\n","display(df_source)  # Show DataFrane contents\n","df_source.describe()  # Show some statistics of numerical fields in the DataFrame"]},{"cell_type":"markdown","metadata":{"id":"hOUm8X7XddIr"},"source":["## Analyze the target sound file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7zsCdeneddIs","scrolled":false},"outputs":[],"source":["TARGET_SOUND_PATH = '213524__garzul__120-bpm-distorded-drum-loop.wav'  # Filename of the target audio we'll reconstruct\n","DATAFRAME_TARGET_FILE_FILENAME = 'dataframe_target.csv'  # DataFrame file where to store the analysis results of the target audio\n","\n","# Analyze the target audio file and store results in a new DataFrame\n","print('Analyzing target sound {0}'.format(TARGET_SOUND_PATH))\n","target_analysis = analyze_sound(TARGET_SOUND_PATH, frame_size=8192)  # Also split audio in chunks of 8192 samples (~185ms)\n","df_target = pd.DataFrame(target_analysis)\n","df_target.to_csv(DATAFRAME_TARGET_FILE_FILENAME)\n","print('Saved target dataframe with {0} entries! {1}'.format(len(df_target), DATAFRAME_TARGET_FILE_FILENAME))\n","\n","# Plot target audio file waveform and show ticks at the start samples of the chunks\n","plt.figure(figsize=(15,5))\n","audio = estd.MonoLoader(filename=TARGET_SOUND_PATH)()\n","plt.plot(audio)\n","plt.vlines(df_target['start_sample'].values, -1, 1, color='red')\n","plt.axis([0, min(len(audio), 44100 * 4), -1, 1])\n","plt.title('Target audio file (first 4 seconds)')\n","plt.show()\n","\n","display(df_target)  # Show data frame contents\n","df_target.describe()  # Show statistics of numerical fields in data frame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SEoLguuqddIs"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":0}